{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbcba58",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchcodec\n",
    "!pip install soundfile\n",
    "!pip install scipy\n",
    "!pip install gTTS\n",
    "!pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3e19c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffwave.inference import predict as diffwave_predict\n",
    "import torch\n",
    "from scipy.io.wavfile import write\n",
    "import numpy as np\n",
    "from data_generation import generate_audio_waveforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c474dff3",
   "metadata": {},
   "source": [
    "Perform the following to get the mel spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6acc0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"The patient is speaking softly about the weather.\",\n",
    "    \"Please bring the red cup from the kitchen.\"\n",
    "]\n",
    "\n",
    "output_dir = \"./audio_wav\"\n",
    "\n",
    "generate_audio_waveforms(sentences, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "62c80f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing: 100%|██████████████████████████████| 3/3 [00:02<00:00,  1.44it/s]\n"
     ]
    }
   ],
   "source": [
    "!python -m diffwave.preprocess ./audio_wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "466bf824",
   "metadata": {},
   "outputs": [],
   "source": [
    "mel = np.load(\"./audio_wav/sentence_2.wav.spec.npy\")  # shape: (n_mels, time)\n",
    "\n",
    "# # Convert to PyTorch tensor\n",
    "mel = torch.from_numpy(mel).float()\n",
    "\n",
    "\n",
    "model_dir = './pretrained_model/diffwave-ljspeech-22kHz-1000578.pt'\n",
    "audio, sample_rate, latent_vars = diffwave_predict(mel, model_dir, fast_sampling=True, expose_latent_vars=True, compute_jacobian=False)\n",
    "write(\"output.wav\", sample_rate, audio.squeeze().cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bcf721",
   "metadata": {},
   "source": [
    "Try injecting latent vars into inference with correct mel spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "db1cacad",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio, sample_rate, __ = diffwave_predict(mel, model_dir, fast_sampling=True, inject_latent_var=(3, latent_vars[3]))\n",
    "write(\"injected_output.wav\", sample_rate, audio.squeeze().cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd252dd7",
   "metadata": {},
   "source": [
    "## Steps to train to fit brain signals into diffusion pipeline\n",
    "1. Get mel spectrograms of all of the GT sentences\n",
    "2. Use those to get latent variables to train\n",
    "3. Train model(s) to give use mel spectrograms and latent variables\n",
    "\n",
    "### Notes on setup\n",
    "- Must choose whether we use fast sampling or not"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffwave_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
